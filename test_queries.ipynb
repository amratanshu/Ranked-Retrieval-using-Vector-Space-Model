{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:  # python 3.x\n",
    "    import pickle\n",
    "    \n",
    "# importing the index from the dictionary.p file\n",
    "\n",
    "with open('dictionary.p', 'rb') as fp:\n",
    "    d = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is just used for finally returning the documents. These data structures (list of documents) are not used in evaluating the queries\n",
    "\n",
    "ag40 = open('wiki_40', encoding=\"utf8\")\n",
    "\n",
    "soup = BeautifulSoup(ag40)\n",
    "\n",
    "docList = soup.findAll('doc')\n",
    "numberDocs = len(docList)\n",
    "docs = []\n",
    "\n",
    "for i in range(numberDocs):\n",
    "    soupTemp = BeautifulSoup(str(docList[i]))\n",
    "    txtTemp = soupTemp.get_text()\n",
    "    docs.append(txtTemp)\n",
    "    \n",
    "import re\n",
    "\n",
    "for i in range(numberDocs):\n",
    "    docs[i] = docs[i].lower()\n",
    "    docs[i] = re.sub(r'[^\\w\\s]','',docs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check whether any of the query terms is in the mentioned document\n",
    "\n",
    "def queryInDoc(tokens,d,docID):\n",
    "    for key in tokens:\n",
    "        if key in d.keys():\n",
    "            travlist = d[key]\n",
    "            #print(travlist)\n",
    "            for i in range(len(travlist)):\n",
    "                if(travlist[i][0] == docID):\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryInDoc2(tokens,d,docID): #returns true for those docs which contain atleast 70% of the query terms\n",
    "    countDoc = 0\n",
    "    countTokens = len(tokens)\n",
    "    \n",
    "    for i in range(countTokens):\n",
    "        #traverse the posting list of token[i]\n",
    "        if tokens[i] in d.keys():\n",
    "            tempList = d[tokens[i]]\n",
    "            for k in tempList:\n",
    "                if k[0] == docID:\n",
    "                    countDoc = countDoc + 1\n",
    "                    break\n",
    "        #else: #this query token is not in any of the documents   \n",
    "        \n",
    "    if countDoc/countTokens >= 0.7:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency of a word in a document\n",
    "\n",
    "def wordFreq(key,d,docID):\n",
    "    if key in d.keys():\n",
    "        travlist = d[key]\n",
    "        for i in range(len(travlist)):\n",
    "            if(travlist[i][0] == docID):\n",
    "                return travlist[i][1]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return a unique token dictionary for a document\n",
    "\n",
    "def uniqueTokens(document):\n",
    "    tokens = nltk.tokenize.word_tokenize(document)\n",
    "    tempDict1 = {}\n",
    "    uniqueTokens = []\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] in tempDict1.keys():\n",
    "            tempDict1[tokens[i]] = tempDict1[tokens[i]] + 1\n",
    "        else:\n",
    "            tempDict1[tokens[i]] = 1\n",
    "    return tempDict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = []\n",
    "queries.append('the modern re-interpretations of classical music')\n",
    "queries.append('As in the Five Hoosier Painters')\n",
    "queries.append('Highway construction')\n",
    "queries.append('school of drama')\n",
    "queries.append('idhar query 5 daalna')\n",
    "queries.append('idhar query 6 daalna')\n",
    "queries.append('Chief Executive Officer')\n",
    "queries.append('medieval architecture')\n",
    "queries.append('university teacher')\n",
    "queries.append('seven quality coach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnTopDocs(d,query):\n",
    "    query = query.lower()\n",
    "    query = re.sub(r'[^\\w\\s]','',query)\n",
    "    query_tokens = nltk.tokenize.word_tokenize(query)\n",
    "    scores = []\n",
    "    queryDict = {}\n",
    "    \n",
    "    for j in range(len(query_tokens)):\n",
    "        if query_tokens[j] in queryDict.keys():\n",
    "            queryDict[query_tokens[j]] = queryDict[query_tokens[j]] + 1\n",
    "        else:\n",
    "            queryDict[query_tokens[j]] = 1\n",
    "    \n",
    "    keys = list(queryDict.keys())\n",
    "    tf = []\n",
    "    idf = []\n",
    "    wt = []\n",
    "    for i in range(len(keys)):\n",
    "        tf.append(queryDict[keys[i]])\n",
    "        if(keys[i] in d.keys()):\n",
    "            idf.append(1 + math.log2(numberDocs/len(d[keys[i]])))\n",
    "        else:\n",
    "            idf.append(0)\n",
    "        wt.append(tf[i]*idf[i])\n",
    "    \n",
    "    sumQuerySquare = 0\n",
    "    for i in range(len(wt)):\n",
    "        sumQuerySquare = sumQuerySquare + wt[i]*wt[i]\n",
    "    sumQueryRoot = math.sqrt(sumQuerySquare)\n",
    "    \n",
    "    for i in range(len(wt)):\n",
    "        wt[i] = wt[i]/sumQueryRoot\n",
    "    \n",
    "    queryKeysWts = {}\n",
    "    for i in range(len(keys)):\n",
    "        queryKeysWts[keys[i]] = wt[i]\n",
    "        \n",
    "    docScores = []\n",
    "    \n",
    "    for i in range(numberDocs):\n",
    "        if queryInDoc(query_tokens,d,i):\n",
    "            docDict = uniqueTokens(docs[i])\n",
    "            docDict2 = {}\n",
    "            docSum = 0\n",
    "            for k in docDict:\n",
    "                tfd = docDict[k]\n",
    "                tfdwt = 1 + math.log2(tfd)\n",
    "                docSum = docSum + tfdwt*tfdwt\n",
    "                docDict2[k] = tfdwt\n",
    "            \n",
    "            docSum = math.sqrt(docSum)\n",
    "            \n",
    "            docScore = 0\n",
    "            for m in range(len(keys)):\n",
    "                token1 = keys[m]\n",
    "                if token1 in docDict:\n",
    "                    docScore = docScore + (docDict2[token1]/docSum)*wt[m]\n",
    "            \n",
    "            docScores.append([docScore,i])\n",
    "    \n",
    "    #docScores = docScores.sort(reverse=True)\n",
    "    return docScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = returnTopDocs(d,queries[9])\n",
    "r = sorted(r,reverse=True)\n",
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.207805907294367, 68],\n",
       " [0.13113833524331556, 1076],\n",
       " [0.1234175640890745, 1754],\n",
       " [0.11578844409676164, 1442],\n",
       " [0.11161599663132674, 1619],\n",
       " [0.10809777561352757, 28],\n",
       " [0.10741571599651598, 3180],\n",
       " [0.10659096869161729, 3445],\n",
       " [0.1060372470842922, 180],\n",
       " [0.09998977908425799, 1314],\n",
       " [0.09830713012883364, 3272],\n",
       " [0.09472720442856188, 957],\n",
       " [0.09282185557170992, 1726],\n",
       " [0.09264508049639647, 329],\n",
       " [0.09216849510028358, 2080],\n",
       " [0.09041490559782114, 1201],\n",
       " [0.08848847983226679, 95],\n",
       " [0.08721561914775114, 2495],\n",
       " [0.08705911540694618, 2879],\n",
       " [0.08293764576961803, 2772],\n",
       " [0.08293764576961803, 2643],\n",
       " [0.08096657758443528, 2040],\n",
       " [0.0805590637432226, 2741],\n",
       " [0.080341848720751, 2607],\n",
       " [0.08030623982706937, 988],\n",
       " [0.0789295205440991, 1482],\n",
       " [0.07891443755441761, 1724],\n",
       " [0.07865835683242706, 1732],\n",
       " [0.07755712807047181, 377],\n",
       " [0.07751374357848474, 1743],\n",
       " [0.07472468207827054, 844],\n",
       " [0.07453380456695043, 102],\n",
       " [0.07451659253979342, 1912],\n",
       " [0.07413045637686629, 2987],\n",
       " [0.07312318974005787, 220],\n",
       " [0.07311597764462492, 2758],\n",
       " [0.07291573326493715, 2781],\n",
       " [0.07219798605818015, 2800],\n",
       " [0.07185965671222927, 2921],\n",
       " [0.0712546489949828, 1568],\n",
       " [0.07076856595321705, 765],\n",
       " [0.06925147297472119, 823],\n",
       " [0.06915467026040967, 2174],\n",
       " [0.06685353215303902, 1010],\n",
       " [0.06632021499433788, 816],\n",
       " [0.0661038662147829, 2142],\n",
       " [0.06585517561235135, 950],\n",
       " [0.06566033582813399, 1178],\n",
       " [0.0627279525908274, 1897],\n",
       " [0.059351969271486525, 2026],\n",
       " [0.05929052117355142, 1542],\n",
       " [0.059009402257070194, 1313],\n",
       " [0.05767772923297743, 1508],\n",
       " [0.05700658769107162, 3537],\n",
       " [0.056168187670396864, 2487],\n",
       " [0.05581329486666877, 156],\n",
       " [0.05544628598843036, 1784],\n",
       " [0.05491813685723769, 212],\n",
       " [0.0545092892094403, 3444],\n",
       " [0.05379257738594027, 3059],\n",
       " [0.05199309593770246, 1808],\n",
       " [0.05139998311144518, 2151],\n",
       " [0.050896191578846256, 3061],\n",
       " [0.04993797995279776, 2393],\n",
       " [0.049358638160567986, 1231],\n",
       " [0.046886787894358004, 2346],\n",
       " [0.04641952731075456, 2978],\n",
       " [0.04615194757755734, 1759],\n",
       " [0.045571077194629134, 3017],\n",
       " [0.04525638000285251, 2141],\n",
       " [0.045023714923047145, 1208],\n",
       " [0.04487556516128792, 598],\n",
       " [0.044314253832363294, 254],\n",
       " [0.04424109522776331, 1805],\n",
       " [0.04423815810217494, 535],\n",
       " [0.043830034604790756, 201],\n",
       " [0.043396881028311046, 2004],\n",
       " [0.042770253491170834, 1008],\n",
       " [0.04271709248807729, 337],\n",
       " [0.042594062271761816, 537],\n",
       " [0.04244004451953884, 3035],\n",
       " [0.04236808180712186, 1402],\n",
       " [0.042281848948881616, 1883],\n",
       " [0.04207476873186173, 1280],\n",
       " [0.04175557218923979, 3529],\n",
       " [0.04161266099307016, 2846],\n",
       " [0.04133329072659541, 2379],\n",
       " [0.04132667438652757, 1807],\n",
       " [0.0411848525748045, 1406],\n",
       " [0.04117706008180551, 1553],\n",
       " [0.04064187931005028, 3385],\n",
       " [0.04047366379989496, 58],\n",
       " [0.040473474959898226, 1588],\n",
       " [0.0403607081108183, 2736],\n",
       " [0.040222275128722736, 92],\n",
       " [0.03971416979518209, 2167],\n",
       " [0.03939257647189194, 2301],\n",
       " [0.038682805225250465, 432],\n",
       " [0.038581475348184444, 3056],\n",
       " [0.03843430083255537, 445],\n",
       " [0.03841927099248872, 2193],\n",
       " [0.038307921428029294, 1222],\n",
       " [0.03817983199002479, 536],\n",
       " [0.037975772604505964, 2215],\n",
       " [0.037417982064047985, 1538],\n",
       " [0.037098299060001776, 1141],\n",
       " [0.0369218099701753, 1481],\n",
       " [0.036916701854376774, 1032],\n",
       " [0.0367509907333246, 1772],\n",
       " [0.036563216096114196, 710],\n",
       " [0.03634533393685731, 2376],\n",
       " [0.03628124154398929, 2289],\n",
       " [0.03621847041780896, 1579],\n",
       " [0.0358350347399319, 3216],\n",
       " [0.03579279003879911, 2476],\n",
       " [0.03569549085608989, 2278],\n",
       " [0.03514543009141007, 1227],\n",
       " [0.03507600270397512, 712],\n",
       " [0.034969427204020444, 113],\n",
       " [0.03483003482024319, 1263],\n",
       " [0.03461847360698206, 1072],\n",
       " [0.03437724828535237, 2923],\n",
       " [0.03424741377765583, 369],\n",
       " [0.03406804633356239, 3486],\n",
       " [0.03390207315043757, 3034],\n",
       " [0.033893144807403866, 335],\n",
       " [0.03384257522008403, 3019],\n",
       " [0.0336852786967178, 2557],\n",
       " [0.03363224119786454, 1342],\n",
       " [0.03334065370914302, 656],\n",
       " [0.033211185613792604, 1875],\n",
       " [0.03299049322948807, 2117],\n",
       " [0.03288262012058607, 717],\n",
       " [0.03276657537782044, 1428],\n",
       " [0.0327313534765863, 1202],\n",
       " [0.03260748161008123, 2911],\n",
       " [0.03231649581639453, 3287],\n",
       " [0.03214617983018436, 3235],\n",
       " [0.031599578819671, 2824],\n",
       " [0.03125267568885141, 2501],\n",
       " [0.031100310835602357, 2178],\n",
       " [0.031065797983209274, 461],\n",
       " [0.030844981974218276, 1148],\n",
       " [0.030750727809221404, 2378],\n",
       " [0.0307300709592006, 701],\n",
       " [0.03051128964754706, 1770],\n",
       " [0.03018164470705322, 3239],\n",
       " [0.029939901924257342, 2794],\n",
       " [0.02984540359371839, 3436],\n",
       " [0.02978101348892769, 302],\n",
       " [0.02964322907385431, 1013],\n",
       " [0.029539303500134256, 98],\n",
       " [0.0295391391922072, 3051],\n",
       " [0.029490821433420522, 1975],\n",
       " [0.029427023628476334, 2717],\n",
       " [0.029417090236038532, 1156],\n",
       " [0.029381133530038434, 3334],\n",
       " [0.029089964562263843, 1631],\n",
       " [0.029030464342717853, 242],\n",
       " [0.02896563615383982, 2032],\n",
       " [0.028840930797854054, 1781],\n",
       " [0.028507076579207338, 492],\n",
       " [0.028355913845050637, 227],\n",
       " [0.028318966731425484, 958],\n",
       " [0.028223696239178624, 2367],\n",
       " [0.02811309720139772, 723],\n",
       " [0.027933998061889287, 2019],\n",
       " [0.027432826027755042, 2646],\n",
       " [0.027426430644742084, 2085],\n",
       " [0.0272733801349689, 3232],\n",
       " [0.02711448503974964, 1705],\n",
       " [0.027057169920951283, 3367],\n",
       " [0.02695487026329004, 1979],\n",
       " [0.026661899076585685, 3166],\n",
       " [0.026522559558052335, 1835],\n",
       " [0.026435972938999394, 1920],\n",
       " [0.026260193034607682, 1071],\n",
       " [0.02581378509373424, 2241],\n",
       " [0.025264108421436452, 130],\n",
       " [0.025228021362831657, 3081],\n",
       " [0.025098872961757935, 708],\n",
       " [0.025037609133984645, 2747],\n",
       " [0.024784246183304683, 3413],\n",
       " [0.024779936283259096, 355],\n",
       " [0.024765874993066355, 62],\n",
       " [0.024676624272512517, 1913],\n",
       " [0.024637138686199083, 632],\n",
       " [0.024362709340827016, 1180],\n",
       " [0.024343052709287605, 433],\n",
       " [0.02418505996838079, 1037],\n",
       " [0.024125543656306876, 2201],\n",
       " [0.023904879885769458, 953],\n",
       " [0.023685339185710263, 385],\n",
       " [0.02366278685679927, 1138],\n",
       " [0.02345729046850665, 2914],\n",
       " [0.023245010218841487, 2899],\n",
       " [0.023164329548000195, 2440],\n",
       " [0.02313429535692108, 3363],\n",
       " [0.022849207270722777, 1498],\n",
       " [0.022624586788365392, 1181],\n",
       " [0.02254958231906733, 2922],\n",
       " [0.022482273343560497, 2651],\n",
       " [0.022421507984547295, 1889],\n",
       " [0.02235235393015615, 1533],\n",
       " [0.021972590683407237, 2723],\n",
       " [0.021912750034879955, 3512],\n",
       " [0.021911817411421924, 3468],\n",
       " [0.021780708105002714, 1507],\n",
       " [0.02177600609404969, 781],\n",
       " [0.02173970777961802, 2191],\n",
       " [0.021721945022747203, 2249],\n",
       " [0.021716134350096904, 657],\n",
       " [0.02165820091127178, 1903],\n",
       " [0.021458814641169124, 1813],\n",
       " [0.021442399899088898, 819],\n",
       " [0.021363593381672076, 3204],\n",
       " [0.021104388594246088, 183],\n",
       " [0.021056650621887447, 2666],\n",
       " [0.021033406507065207, 1630],\n",
       " [0.020992513542821802, 2029],\n",
       " [0.0209369455138602, 1250],\n",
       " [0.020927318705178142, 956],\n",
       " [0.020851731961701016, 389],\n",
       " [0.02076856877547601, 508],\n",
       " [0.02075837142403633, 910],\n",
       " [0.020713251374438926, 362],\n",
       " [0.020556066082843313, 3038],\n",
       " [0.02052689053822917, 2564],\n",
       " [0.020497493758704726, 515],\n",
       " [0.020379292987057058, 202],\n",
       " [0.020312973390450115, 3497],\n",
       " [0.020205596737922202, 237],\n",
       " [0.019813237191198364, 873],\n",
       " [0.019642979886457534, 2604],\n",
       " [0.01957371470832732, 532],\n",
       " [0.019526144818548034, 3338],\n",
       " [0.0193428127056556, 3071],\n",
       " [0.01933393957438983, 2224],\n",
       " [0.019237437769714684, 3273],\n",
       " [0.019203127172002166, 968],\n",
       " [0.019059777230385093, 2698],\n",
       " [0.019044279988278498, 1422],\n",
       " [0.018994021005112747, 378],\n",
       " [0.018969089844565554, 1600],\n",
       " [0.018801211897548104, 1085],\n",
       " [0.018674393914778133, 1279],\n",
       " [0.0186194520697924, 1465],\n",
       " [0.01850638981722208, 453],\n",
       " [0.01836092756370971, 705],\n",
       " [0.018328985588229738, 3343],\n",
       " [0.01819417387529148, 32],\n",
       " [0.018038085994277475, 1858],\n",
       " [0.017839230807542877, 1682],\n",
       " [0.017636106661418377, 2678],\n",
       " [0.017631339944886505, 1129],\n",
       " [0.017622167289384563, 1777],\n",
       " [0.01755353597294522, 1368],\n",
       " [0.01749244248433873, 365],\n",
       " [0.017465911545401277, 2194],\n",
       " [0.01733807192118969, 1718],\n",
       " [0.017335974710052878, 1587],\n",
       " [0.017320804851385825, 2084],\n",
       " [0.01723222470954105, 2],\n",
       " [0.017189781879606632, 2485],\n",
       " [0.017158478209251603, 1940],\n",
       " [0.01694120102141352, 1739],\n",
       " [0.016568106521640955, 1505],\n",
       " [0.016551745556662587, 2859],\n",
       " [0.01648025204242677, 134],\n",
       " [0.016439362794919626, 2489],\n",
       " [0.016226044332034905, 1922],\n",
       " [0.01616363290409288, 2590],\n",
       " [0.01606386380189525, 3066],\n",
       " [0.015962100362546097, 159],\n",
       " [0.01593261494631149, 3397],\n",
       " [0.015871570251818314, 1613],\n",
       " [0.015277320477179963, 1124],\n",
       " [0.01495423251552925, 3025],\n",
       " [0.014941224991352154, 1211],\n",
       " [0.014936125401689426, 1666],\n",
       " [0.014853452025100333, 3504],\n",
       " [0.01483246249962689, 1471],\n",
       " [0.014785800649349696, 2878],\n",
       " [0.014746243539211149, 2252],\n",
       " [0.014715055470562571, 2047],\n",
       " [0.014472397593947738, 2462],\n",
       " [0.014255497418147014, 618],\n",
       " [0.014110282230521205, 2139],\n",
       " [0.013786638554553527, 3021],\n",
       " [0.013392661654236877, 1924],\n",
       " [0.01321408769251232, 2783],\n",
       " [0.012967548689412849, 3155],\n",
       " [0.01295760599996621, 2740],\n",
       " [0.012823136531061315, 153],\n",
       " [0.01260959973065953, 1001],\n",
       " [0.012565853024951647, 150],\n",
       " [0.012519313208012443, 161],\n",
       " [0.01244917453056075, 2819],\n",
       " [0.012087994039000042, 1321],\n",
       " [0.012023395248600638, 2839],\n",
       " [0.011960999177539965, 1401],\n",
       " [0.011949424813188666, 516],\n",
       " [0.011823758599225272, 446],\n",
       " [0.011807917967065004, 46],\n",
       " [0.01180754811444329, 3339],\n",
       " [0.011736796477612714, 5],\n",
       " [0.011016274686843497, 2609],\n",
       " [0.010986289663621291, 2394],\n",
       " [0.010944755044510823, 1722],\n",
       " [0.010847887717284581, 3259],\n",
       " [0.010794115196936198, 162],\n",
       " [0.010547485105145641, 1213],\n",
       " [0.010323337376401958, 1773],\n",
       " [0.010016943807913865, 2888],\n",
       " [0.009962763551298553, 3248],\n",
       " [0.009667018183539315, 2190],\n",
       " [0.009301514967654145, 1750],\n",
       " [0.009283973622139991, 509],\n",
       " [0.0092039061447418, 3217],\n",
       " [0.009111675182864562, 2038],\n",
       " [0.009011644537028126, 3176],\n",
       " [0.00888457847386732, 2086],\n",
       " [0.008854086512821182, 1292],\n",
       " [0.008763848952526023, 392],\n",
       " [0.008722224773195049, 468],\n",
       " [0.008456463796780516, 559],\n",
       " [0.008435553852679701, 3336],\n",
       " [0.007109549684181483, 1045],\n",
       " [0.0032309681830722517, 3527]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nedgar wingard\\n\\nedgar ramey wingard september 21 1878  july 31 1927 was an american football basketball and baseball coach and college athletics administrator he served as the head football coach at seven different schools ohio northern university 1903 butler university 19041905 the university of pittsburgh 1906 louisiana state university 19071908 the university of maine 19101911 susquehanna university 19161917 1919 19241925 and bucknell university 1918 compling a career record of 77395 in 1908 wingard led his lsu team to a record of 100 the team has been recognized as a national champion by the national championship foundation although lsu does not officially claim a national title that season wingard was the head coach of the basketball team at butler from 1904 to 1906 and the head coach of the first lsu tigers basketball team during the 190809 season he also coached the lsu tigers baseball team in 1908 and 1909 and the baseball team at maine in 1911\\n\\nwingard died of a cerebral hemorrhage in the summer of 1927 at a hospital in selinsgrove pennsylvania\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1076]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idfofterm(word, dictionary, N): #N is the number of Documents total \n",
    "    if word in dictionary.keys():\n",
    "        return math.log2(N / len(dictionary[word]))\n",
    "    else:\n",
    "        return -1 #returns -1 if the idf is +infinity (word not in any document)\n",
    "\n",
    "\n",
    "def returnTopDocsHIGHIDF(d,query):\n",
    "    query = query.lower()\n",
    "    query = re.sub(r'[^\\w\\s]','',query)\n",
    "    query_tokens = nltk.tokenize.word_tokenize(query)\n",
    "    scores = []\n",
    "    queryDict = {}\n",
    "    \n",
    "    #print('The length of [query_tokens] is')\n",
    "    #print(len(query_tokens))\n",
    "    #print(query_tokens)\n",
    "    \n",
    "    toDelete = {}\n",
    "    #removing the lowidf terms from query_tokens (all instances)\n",
    "    for term in query_tokens:\n",
    "        if idfofterm(term, d, numberDocs)<2.00:\n",
    "            if term not in toDelete.keys():\n",
    "                toDelete[term] = 1\n",
    "    \n",
    "    for key in toDelete:\n",
    "        while key in query_tokens: query_tokens.remove(key)\n",
    "\n",
    "    print('The length of [query_tokens] without lowIDF terms is')\n",
    "    print(len(query_tokens)) \n",
    "    print(query_tokens)\n",
    "    \n",
    "    \n",
    "    for j in range(len(query_tokens)):\n",
    "        if query_tokens[j] in queryDict.keys():\n",
    "            queryDict[query_tokens[j]] = queryDict[query_tokens[j]] + 1\n",
    "        else:\n",
    "            queryDict[query_tokens[j]] = 1\n",
    "      \n",
    "    keys = list(queryDict.keys())\n",
    "    tf = []\n",
    "    idf = []\n",
    "    wt = []\n",
    "    for i in range(len(keys)):\n",
    "        tf.append(queryDict[keys[i]])\n",
    "        if(keys[i] in d.keys()):\n",
    "            idf.append(1 + math.log2(numberDocs/len(d[keys[i]])))\n",
    "        else:\n",
    "            idf.append(0)\n",
    "        wt.append(tf[i]*idf[i])\n",
    "    \n",
    "    sumQuerySquare = 0\n",
    "    for i in range(len(wt)):\n",
    "        sumQuerySquare = sumQuerySquare + wt[i]*wt[i]\n",
    "    sumQueryRoot = math.sqrt(sumQuerySquare)\n",
    "    \n",
    "    for i in range(len(wt)):\n",
    "        wt[i] = wt[i]/sumQueryRoot\n",
    "    \n",
    "    queryKeysWts = {}\n",
    "    for i in range(len(keys)):\n",
    "        queryKeysWts[keys[i]] = wt[i]\n",
    "        \n",
    "    docScores = []\n",
    "    \n",
    "    for i in range(numberDocs):\n",
    "        if queryInDoc(query_tokens,d,i):\n",
    "            docDict = uniqueTokens(docs[i])\n",
    "            docDict2 = {}\n",
    "            docSum = 0\n",
    "            for k in docDict:\n",
    "                tfd = docDict[k]\n",
    "                tfdwt = 1 + math.log2(tfd)\n",
    "                docSum = docSum + tfdwt*tfdwt\n",
    "                docDict2[k] = tfdwt\n",
    "            \n",
    "            docSum = math.sqrt(docSum)\n",
    "            \n",
    "            docScore = 0\n",
    "            for m in range(len(keys)):\n",
    "                token1 = keys[m]\n",
    "                if token1 in docDict:\n",
    "                    docScore = docScore + (docDict2[token1]/docSum)*wt[m]\n",
    "            \n",
    "            docScores.append([docScore,i])\n",
    "    \n",
    "    #docScores = docScores.sort(reverse=True)\n",
    "    return docScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnTopDocsMANYQUERYTERMS(d,query):\n",
    "    query = query.lower()\n",
    "    query = re.sub(r'[^\\w\\s]','',query)\n",
    "    query_tokens = nltk.tokenize.word_tokenize(query)\n",
    "    scores = []\n",
    "    queryDict = {}\n",
    "\n",
    "    for j in range(len(query_tokens)):\n",
    "        if query_tokens[j] in queryDict.keys():\n",
    "            queryDict[query_tokens[j]] = queryDict[query_tokens[j]] + 1\n",
    "        else:\n",
    "            queryDict[query_tokens[j]] = 1\n",
    "    \n",
    "    keys = list(queryDict.keys())\n",
    "    tf = []\n",
    "    idf = []\n",
    "    wt = []\n",
    "    for i in range(len(keys)):\n",
    "        tf.append(queryDict[keys[i]])\n",
    "        if(keys[i] in d.keys()):\n",
    "            idf.append(1 + math.log2(numberDocs/len(d[keys[i]])))\n",
    "        else:\n",
    "            idf.append(0)\n",
    "        wt.append(tf[i]*idf[i])\n",
    "    \n",
    "    sumQuerySquare = 0\n",
    "    for i in range(len(wt)):\n",
    "        sumQuerySquare = sumQuerySquare + wt[i]*wt[i]\n",
    "    sumQueryRoot = math.sqrt(sumQuerySquare)\n",
    "    \n",
    "    for i in range(len(wt)):\n",
    "        wt[i] = wt[i]/sumQueryRoot\n",
    "    \n",
    "    queryKeysWts = {}\n",
    "    for i in range(len(keys)):\n",
    "        queryKeysWts[keys[i]] = wt[i]\n",
    "        \n",
    "    docScores = []\n",
    "    \n",
    "    for i in range(numberDocs):\n",
    "        if queryInDoc2(query_tokens,d,i):\n",
    "            docDict = uniqueTokens(docs[i])\n",
    "            docDict2 = {}\n",
    "            docSum = 0\n",
    "            for k in docDict:\n",
    "                tfd = docDict[k]\n",
    "                tfdwt = 1 + math.log2(tfd)\n",
    "                docSum = docSum + tfdwt*tfdwt\n",
    "                docDict2[k] = tfdwt\n",
    "            \n",
    "            docSum = math.sqrt(docSum)\n",
    "            \n",
    "            docScore = 0\n",
    "            for m in range(len(keys)):\n",
    "                token1 = keys[m]\n",
    "                if token1 in docDict:\n",
    "                    docScore = docScore + (docDict2[token1]/docSum)*wt[m]\n",
    "            \n",
    "            docScores.append([docScore,i])\n",
    "    \n",
    "    #docScores = docScores.sort(reverse=True)\n",
    "    return docScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnTopDocsBOTH(d,query):\n",
    "    query = query.lower()\n",
    "    query = re.sub(r'[^\\w\\s]','',query)\n",
    "    query_tokens = nltk.tokenize.word_tokenize(query)\n",
    "    scores = []\n",
    "    queryDict = {}\n",
    "    \n",
    "    print('The length of [query_tokens] is')\n",
    "    print(len(query_tokens))\n",
    "    print(query_tokens)\n",
    "    \n",
    "    toDelete = {}\n",
    "    #removing the lowidf terms from query_tokens (all instances)\n",
    "    for term in query_tokens:\n",
    "        if idfofterm(term, d, numberDocs)<2.00:\n",
    "            if term not in toDelete.keys():\n",
    "                toDelete[term] = 1\n",
    "    \n",
    "    for key in toDelete:\n",
    "        while key in query_tokens: query_tokens.remove(key)\n",
    "\n",
    "    print('The length of [query_tokens] without lowIDF terms is')\n",
    "    print(len(query_tokens)) \n",
    "    print(query_tokens)\n",
    "    \n",
    "    \n",
    "    for j in range(len(query_tokens)):\n",
    "        if query_tokens[j] in queryDict.keys():\n",
    "            queryDict[query_tokens[j]] = queryDict[query_tokens[j]] + 1\n",
    "        else:\n",
    "            queryDict[query_tokens[j]] = 1\n",
    " \n",
    "    keys = list(queryDict.keys())\n",
    "    tf = []\n",
    "    idf = []\n",
    "    wt = []\n",
    "    for i in range(len(keys)):\n",
    "        tf.append(queryDict[keys[i]])\n",
    "        if(keys[i] in d.keys()):\n",
    "            idf.append(1 + math.log2(numberDocs/len(d[keys[i]])))\n",
    "        else:\n",
    "            idf.append(0)\n",
    "        wt.append(tf[i]*idf[i])\n",
    "    \n",
    "    sumQuerySquare = 0\n",
    "    for i in range(len(wt)):\n",
    "        sumQuerySquare = sumQuerySquare + wt[i]*wt[i]\n",
    "    sumQueryRoot = math.sqrt(sumQuerySquare)\n",
    "    \n",
    "    for i in range(len(wt)):\n",
    "        wt[i] = wt[i]/sumQueryRoot\n",
    "    \n",
    "    queryKeysWts = {}\n",
    "    for i in range(len(keys)):\n",
    "        queryKeysWts[keys[i]] = wt[i]\n",
    "        \n",
    "    docScores = []\n",
    "    \n",
    "    for i in range(numberDocs):\n",
    "        if queryInDoc2(query_tokens,d,i):\n",
    "            docDict = uniqueTokens(docs[i])\n",
    "            docDict2 = {}\n",
    "            docSum = 0\n",
    "            for k in docDict:\n",
    "                tfd = docDict[k]\n",
    "                tfdwt = 1 + math.log2(tfd)\n",
    "                docSum = docSum + tfdwt*tfdwt\n",
    "                docDict2[k] = tfdwt\n",
    "            \n",
    "            docSum = math.sqrt(docSum)\n",
    "            \n",
    "            docScore = 0\n",
    "            for m in range(len(keys)):\n",
    "                token1 = keys[m]\n",
    "                if token1 in docDict:\n",
    "                    docScore = docScore + (docDict2[token1]/docSum)*wt[m]\n",
    "            \n",
    "            docScores.append([docScore,i])\n",
    "    \n",
    "    #docScores = docScores.sort(reverse=True)\n",
    "    return docScores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
